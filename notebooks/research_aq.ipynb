{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a82e1ba91354e5095b22dcc1a74c0ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e66bea113c1946a5866912b203a826c5",
              "IPY_MODEL_da40f056eebe412b9f3a368a9d070690",
              "IPY_MODEL_4861541631df4cbd92cc274198460b72"
            ],
            "layout": "IPY_MODEL_ec672e3be13b498999169ab36f62b346"
          }
        },
        "e66bea113c1946a5866912b203a826c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_588f73f10ca74b7eba07fe3f8d34424a",
            "placeholder": "​",
            "style": "IPY_MODEL_8b7047d9497644f68d7bb42d3cd08b1e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "da40f056eebe412b9f3a368a9d070690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba367ceca0b54905b66c6fe57e99a2c8",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5f875c9cff9417594df37c64b0e1224",
            "value": 4
          }
        },
        "4861541631df4cbd92cc274198460b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_def70062fbe4478f9efa50e58d87e475",
            "placeholder": "​",
            "style": "IPY_MODEL_5b864d2166fe4242ac62cd38a0aac8b9",
            "value": " 4/4 [01:20&lt;00:00, 17.12s/it]"
          }
        },
        "ec672e3be13b498999169ab36f62b346": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "588f73f10ca74b7eba07fe3f8d34424a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b7047d9497644f68d7bb42d3cd08b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba367ceca0b54905b66c6fe57e99a2c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5f875c9cff9417594df37c64b0e1224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "def70062fbe4478f9efa50e58d87e475": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b864d2166fe4242ac62cd38a0aac8b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## load required libraries"
      ],
      "metadata": {
        "id": "uQ4_lzsgWPn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community pypdf bitsandbytes"
      ],
      "metadata": {
        "id": "SZFetMIzWWAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb rouge"
      ],
      "metadata": {
        "id": "GpVgta2AWX3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "AFlUE808qhbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "-hQ2mp1ZnJTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import pickle\n",
        "#import umap\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Tuple, Dict"
      ],
      "metadata": {
        "id": "JtDelRKupDDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter,RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.base import Embeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from transformers import pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "from langchain.embeddings.base import Embeddings"
      ],
      "metadata": {
        "id": "sOqtFRKXWjYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "explore the mims-harvard/Clinical-knowledge-embeddings\n"
      ],
      "metadata": {
        "id": "ndUaBUPtWyBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read in embeddings\n",
        "embed_mat  = pickle.load(open(\"full_h_embed_hms.pkl\", 'rb')).numpy()\n",
        "\n",
        "## if the pickle file is not compatible, there's also a csv version (tab-delimited)\n",
        "#embed_mat = np.loadtxt(\"full_h_embed_hms.csv\")\n",
        "\n",
        "# mapping file\n",
        "node_map_df = pd.read_csv(\"new_node_map_df.csv\")\n",
        "\n",
        "num_embeddings = embed_mat.shape[0]\n",
        "dim = embed_mat.shape[1]\n",
        "\n",
        "print(\"There are %d clinical concept embeddings that are size 1x%d\" % (num_embeddings, dim))\n",
        "ntypes = node_map_df['ntype'].unique()\n",
        "ind_min = node_map_df['global_graph_index'].min()\n",
        "ind_max = node_map_df['global_graph_index'].max()\n",
        "\n",
        "print(\"The map dataframe contains nodes for the following types of codes: {}\".format(ntypes))\n",
        "print(\"Each embedding has a corresponding global_graph_index which takes sequential values from {} to {}.\".format(ind_min, ind_max))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4fX1u5NqCAn",
        "outputId": "94a874b6-e229-4529-fb8a-2ec8292fdb8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 67124 clinical concept embeddings that are size 1x128\n",
            "The map dataframe contains nodes for the following types of codes: ['CPT' 'ICD9CM' 'LNC' 'PHECODE' 'RXNORM' 'SNOMEDCT_US' 'ATC4']\n",
            "Each embedding has a corresponding global_graph_index which takes sequential values from 0 to 67123.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "node_map_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uy0w3sqMtMgP",
        "outputId": "a286be32-3e46-4181-d1c0-4b15e9e03846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  ntype                           node_name  node_id  global_graph_index\n",
              "0   CPT                             Vaccine    90749                   0\n",
              "1   CPT                     Cholera vaccine    90625                   1\n",
              "2   CPT  Endoscopy Procedures on the Rectum  1007622                   2\n",
              "3   CPT             Sigmoidoscopy, flexible  1007635                   3\n",
              "4   CPT  Intradermal tuberculosis skin test    86580                   4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74a42fcd-0e8e-4b63-be9d-828ba088faf9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ntype</th>\n",
              "      <th>node_name</th>\n",
              "      <th>node_id</th>\n",
              "      <th>global_graph_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CPT</td>\n",
              "      <td>Vaccine</td>\n",
              "      <td>90749</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CPT</td>\n",
              "      <td>Cholera vaccine</td>\n",
              "      <td>90625</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CPT</td>\n",
              "      <td>Endoscopy Procedures on the Rectum</td>\n",
              "      <td>1007622</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CPT</td>\n",
              "      <td>Sigmoidoscopy, flexible</td>\n",
              "      <td>1007635</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CPT</td>\n",
              "      <td>Intradermal tuberculosis skin test</td>\n",
              "      <td>86580</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74a42fcd-0e8e-4b63-be9d-828ba088faf9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-74a42fcd-0e8e-4b63-be9d-828ba088faf9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-74a42fcd-0e8e-4b63-be9d-828ba088faf9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2f8b5fd0-89e2-4837-b4d1-3c52986adfa2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2f8b5fd0-89e2-4837-b4d1-3c52986adfa2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2f8b5fd0-89e2-4837-b4d1-3c52986adfa2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "node_map_df",
              "summary": "{\n  \"name\": \"node_map_df\",\n  \"rows\": 67124,\n  \"fields\": [\n    {\n      \"column\": \"ntype\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"CPT\",\n          \"ICD9CM\",\n          \"SNOMEDCT_US\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"node_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 59702,\n        \"samples\": [\n          \"Deep necrosis of underlying tissues due to burn [deep third degree] of breast, without mention of loss of breast\",\n          \"Motility\",\n          \"Intracranial vessel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"node_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 65831,\n        \"samples\": [\n          \"2589008\",\n          \"444.09\",\n          \"144451009\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"global_graph_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19377,\n        \"min\": 0,\n        \"max\": 67123,\n        \"num_unique_values\": 67124,\n        \"samples\": [\n          63815,\n          23994,\n          38338\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "node_map_df[node_map_df['node_id']=='LA22002-2']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "qMpSfwKwTThe",
        "outputId": "964b99ca-0787-40e8-9c88-111d30783665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      ntype node_name    node_id  global_graph_index\n",
              "16246   LNC        HI  LA22002-2               16246"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-62f70da5-95d0-4dc5-836d-d9553f136eb0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ntype</th>\n",
              "      <th>node_name</th>\n",
              "      <th>node_id</th>\n",
              "      <th>global_graph_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16246</th>\n",
              "      <td>LNC</td>\n",
              "      <td>HI</td>\n",
              "      <td>LA22002-2</td>\n",
              "      <td>16246</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62f70da5-95d0-4dc5-836d-d9553f136eb0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-62f70da5-95d0-4dc5-836d-d9553f136eb0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-62f70da5-95d0-4dc5-836d-d9553f136eb0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"node_map_df[node_map_df['node_id']=='LA22002-2']\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"ntype\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"LNC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"node_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"HI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"node_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"LA22002-2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"global_graph_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 16246,\n        \"max\": 16246,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          16246\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(embed_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7Vspt32aEvv",
        "outputId": "4da74e29-176d-4d5f-a720-77d9a41dcd2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67124"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(embed_mat) #67124\n",
        "len(embed_mat[0]) #128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECVwJYlntTwz",
        "outputId": "97d1506f-49ac-4c5f-ddb0-31748a4a8700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# can query by node name or id; make sure to specify the node type if you're\n",
        "# looking at a specific clinical vocabulary\n",
        "ind = node_map_df.loc[(node_map_df['node_name'] == 'Asthma') & (node_map_df['ntype'] == 'ICD9CM')]['global_graph_index'].values[0]\n",
        "\n",
        "#embed_mat[ind]"
      ],
      "metadata": {
        "id": "M65aSVZcqB9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build vector DB"
      ],
      "metadata": {
        "id": "shqrjlYoWtMC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### load clinical knowledge embedding and pdf research paper"
      ],
      "metadata": {
        "id": "LIbYaKI1woCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# load clinical embeddings and mapping metadata file\n",
        "embed_mat = pickle.load(open(\"full_h_embed_hms.pkl\", 'rb')).numpy()\n",
        "node_map_df = pd.read_csv(\"new_node_map_df.csv\")"
      ],
      "metadata": {
        "id": "rtuYi0ITCopZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pdf_file=\"/content/Slamon-DJ-text.pdf\"\n",
        "\n",
        "loader = PyPDFLoader(pdf_file)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "-jcGz4xf7OOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pdf_file=\"/content/Slamon-DJ-text.pdf\"\n",
        "\n",
        "loader = PyPDFLoader(pdf_file)\n",
        "documents = loader.load()\n",
        "\n",
        "for doc in documents:\n",
        "    doc.page_content = doc.page_content.replace('\\n', ' ')\n",
        "    doc.page_content=doc.page_content.replace('\\xad', '')\n",
        "\n",
        "    # Split the documents into smaller text chunks for better retrieval.\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "docs = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "yzh6-3iu7OMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#documents"
      ],
      "metadata": {
        "id": "cCF8r3ul7VIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the documents into smaller text chunks for better retrieval.\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "docs = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "e0NW7DG79-Op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXMJjq5Q-ATf",
        "outputId": "91d2ab22-b9de-4c19-d5bb-5302936ab362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'producer': 'Acrobat Pro 24 Paper Capture Plug-in', 'creator': 'PyPDF', 'creationdate': '2007-01-15T15:29:22+00:00', 'moddate': '2025-03-02T13:15:22-06:00', 'rgid': 'PB:19364043_AS:101511233277955@1401213572478', 'source': '/content/Slamon-DJ-text.pdf', 'total_pages': 5, 'page': 0, 'page_label': '1'}, page_content='on January 15, 2007 www.sciencemag.orgDownloaded from  BIOM 255 (Leffert) – Discussion Feb. 1, 2007 Human Breast Cancer: Correlation of  Relapse and Survival with Amplification  of the HER-2/neu Oncogene  DENNIS J. SLAMON, * GARY M. CLARK, STEVEN G. WONG, WENDY J. LEVIN,  AXEL ULLRICH, WILLIAM L. McGUIRE  The HER-2/neu oncog is a member of the erB-like  oncogene family, and IS related to, but distinct from, the  epidermal growth factor receptor. This gene has been  shown to be amplified in human breast cancer cell lines.  In the current study, alterations of the gene in 189  primary human breast cancers were investigated. HER -2/  neu was found to be amplified from 2-to greater than 20- fold in 30% of the tum.ors. Correlation of gene amplifica- tion with several disease parameters was evaluated. Am plification of the HER -2/neu gene was a significant pre dictor of both overall survival and time to relapsin  patients with breast cancer. It retained its sign even when adjustments were')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZCiEDumIYcV",
        "outputId": "c9af5f45-23fb-453a-e4b9-5827d345f542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5Q7IqENANBg",
        "outputId": "e152857a-6c03-4911-cd97-b2fd7bc93036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combind clinical embedding with a text embedding"
      ],
      "metadata": {
        "id": "Hs1F-Krbs7Cu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class ClinicalEmbeddings:\n",
        "    \"\"\"\n",
        "    Custom embedding class that uses a one-to-one mapping in node_map_df.\n",
        "    For a given text (assumed to match a 'node_name'), it retrieves the corresponding\n",
        "    embedding from embed_mat based on the 'global_graph_index'. If multiple matches are found,\n",
        "    it concatenates them (up to a fixed maximum) and pads if needed.\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_mat: np.ndarray, node_map_df: pd.DataFrame):\n",
        "        self.embed_mat = embed_mat\n",
        "        self.node_map_df = node_map_df\n",
        "\n",
        "    def embed_query(self, text: str, max_matches: int = 6) -> Tuple[List[float], Dict]:\n",
        "        text_lower = text.lower()\n",
        "        # use regex to match complete words only\n",
        "        matches = self.node_map_df[\n",
        "            self.node_map_df['node_name'].apply(\n",
        "                lambda x: re.search(r'\\b' + re.escape(x.lower()) + r'\\b', text_lower) is not None\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        if not matches.empty:\n",
        "            # sort matches by the length of node_name in descending order\n",
        "            matches = matches.assign(name_length=matches['node_name'].str.len())\n",
        "            matches = matches.sort_values(by='name_length', ascending=False)\n",
        "     #       print(\"Matched rows:\", matches[['node_name', 'node_id', 'global_graph_index']])\n",
        "\n",
        "            embeddings = []\n",
        "            matched_names = []\n",
        "            node_ids = []\n",
        "            global_graph_indices = []\n",
        "            # iterate over the sorted matches\n",
        "            for _, row in matches.iterrows():\n",
        "                index = int(row['global_graph_index'])\n",
        "                embeddings.append(np.array(self.embed_mat[index].tolist()))\n",
        "                matched_names.append(row['node_name'].lower())\n",
        "                node_ids.append(row['node_id'])\n",
        "                global_graph_indices.append(row['global_graph_index'])\n",
        "\n",
        "            # enforce a fixed number of matches by truncating or padding\n",
        "            if len(embeddings) < max_matches:\n",
        "                pad_length = max_matches - len(embeddings)\n",
        "                zero_embedding = np.zeros_like(embeddings[0])\n",
        "                embeddings.extend([zero_embedding] * pad_length)\n",
        "                matched_names.extend([\"none\"] * pad_length)\n",
        "                node_ids.extend([\"none\"] * pad_length)\n",
        "                global_graph_indices.extend([\"none\"] * pad_length)\n",
        "            elif len(embeddings) > max_matches:\n",
        "                embeddings = embeddings[:max_matches]\n",
        "                matched_names = matched_names[:max_matches]\n",
        "                node_ids = node_ids[:max_matches]\n",
        "                global_graph_indices = global_graph_indices[:max_matches]\n",
        "\n",
        "            # concatenate embeddings into a single fixed-size vector.\n",
        "            combined_embedding = np.concatenate(embeddings).tolist()\n",
        "            metadata = {\n",
        "                \"matched_concepts\": \", \".join(matched_names),\n",
        "               \"node_ids\": \", \".join(map(str, node_ids)),\n",
        "               \"global_graph_indices\": \", \".join(map(str, global_graph_indices))\n",
        "            }\n",
        "            return combined_embedding, metadata\n",
        "        else:\n",
        "            # if no matches: return default embedding and None for node_id and global_graph_index\n",
        "            default_embedding = self.embed_mat[0].tolist()\n",
        "            default_metadata = {\"matched_concepts\": \"default\", \"node_ids\": None, \"global_graph_indices\": None}\n",
        "            return default_embedding, default_metadata\n",
        "\n",
        "    def embed_documents(self, texts: List[str]) -> Tuple[List[List[float]], List[Dict]]:\n",
        "        embeddings = []\n",
        "        metadatas = []\n",
        "        for text in texts:\n",
        "            emb, meta = self.embed_query(text)\n",
        "            embeddings.append(emb)\n",
        "            metadatas.append(meta)\n",
        "        return embeddings, metadatas\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dwjni7pEZrer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class SentenceTransformerEmbeddings(Embeddings):\n",
        "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "\n",
        "    def embed_query(self, text: str) -> list[float]:\n",
        "        return self.model.encode(text).tolist()\n",
        "\n",
        "    def embed_documents(self, texts: list[str]) -> list[list[float]]:\n",
        "        return [self.embed_query(text) for text in texts]\n",
        "\n",
        "\n",
        "from typing import List, Tuple, Dict\n",
        "import numpy as np\n",
        "from langchain.embeddings.base import Embeddings\n",
        "\n",
        "class CombinedEmbeddings(Embeddings):\n",
        "    def __init__(self, clinical_emb: ClinicalEmbeddings, regular_emb: SentenceTransformerEmbeddings):\n",
        "        self.clinical_emb = clinical_emb\n",
        "        self.regular_emb = regular_emb\n",
        "\n",
        "    def combine(self, clinical_embedding: List[float], regular_embedding: List[float]) -> List[float]:\n",
        "        \"\"\"Concatenates the clinical embedding vector with the regular embedding vector.\"\"\"\n",
        "        return clinical_embedding + regular_embedding\n",
        "\n",
        "    def embed_query(self, text: str) -> Tuple[List[float], Dict]:\n",
        "        # Get the clinical embedding and its metadata\n",
        "        clinical_embedding, clinical_metadata = self.clinical_emb.embed_query(text)\n",
        "        # Get the regular embedding\n",
        "        regular_embedding = self.regular_emb.embed_query(text)\n",
        "        # Concatenate the embeddings\n",
        "        combined_embedding = self.combine(clinical_embedding, regular_embedding)\n",
        "\n",
        "        # Build metadata including matched concepts, node_id, and global_graph_index\n",
        "        metadata = {\n",
        "            \"matched_concepts\": clinical_metadata.get(\"matched_concepts\", \"default\"),\n",
        "            \"node_ids\": clinical_metadata.get(\"node_ids\", None),\n",
        "            \"global_graph_indices\": clinical_metadata.get(\"global_graph_indices\", None)\n",
        "        }\n",
        "        return combined_embedding, metadata\n",
        "\n",
        "    def embed_documents(self, texts: List[str]) -> Tuple[List[List[float]], List[Dict]]:\n",
        "        embeddings = []\n",
        "        metadatas = []\n",
        "        for text in texts:\n",
        "            emb, meta = self.embed_query(text)\n",
        "            embeddings.append(emb)\n",
        "            metadatas.append(meta)\n",
        "        return embeddings, metadatas\n",
        "\n"
      ],
      "metadata": {
        "id": "bytTxd5rmABn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine Function: combine a single clinical embedding (a list of floats) and a regular embedding (another list of floats) and concatenates them.\n",
        "\n",
        "Dimension: every query returns one clinical vector (e.g. 128*6 dimensions, which is the fixed size after concatenating/padding) plus the regular embedding (e.g. 384 dimensions), yielding a combined vector of 1152 dimensions."
      ],
      "metadata": {
        "id": "KxeB5Rysr-Fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# instantiate the regular embeddings using SentenceTransformer\n",
        "regular_emb = SentenceTransformerEmbeddings(\"all-MiniLM-L6-v2\")\n",
        "# instantiate the clinical embeddings\n",
        "clinical_emb = ClinicalEmbeddings(embed_mat, node_map_df)\n",
        "#  the combined embedding model\n",
        "combined_emb = CombinedEmbeddings(clinical_emb, regular_emb)  # Now an instance of CombinedEmbeddings\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeT94GZymco5",
        "outputId": "5787143a-ee84-42c9-86e7-e54efa75986f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(node_map_df.head())\n",
        "print(node_map_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8B737_b7w7j",
        "outputId": "9748d8aa-19aa-4dac-cd49-f95ab252b62f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ntype                           node_name  node_id  global_graph_index\n",
            "0   CPT                             Vaccine    90749                   0\n",
            "1   CPT                     Cholera vaccine    90625                   1\n",
            "2   CPT  Endoscopy Procedures on the Rectum  1007622                   2\n",
            "3   CPT             Sigmoidoscopy, flexible  1007635                   3\n",
            "4   CPT  Intradermal tuberculosis skin test    86580                   4\n",
            "Index(['ntype', 'node_name', 'node_id', 'global_graph_index'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #get embeddings and metadatas for the pdf research paper\n",
        "embeddings, metadatas = combined_emb.embed_documents([d.page_content for d in docs])"
      ],
      "metadata": {
        "id": "Xjj2XfXFJXUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadatas[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_sas6vZJXQ2",
        "outputId": "6a19f0d8-c45e-49eb-cbac-b66677a05de7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'matched_concepts': 'epidermal growth factor receptor, epidermal growth factor, epidermal growth factor, breast cancer, breast cancer, breast cancer',\n",
              " 'node_ids': 'LP18396-9, LP18547-7, 1427158, LA14283-8, 174.0, 254837009',\n",
              " 'global_graph_indices': '22057, 22056, 26311, 17249, 24336, 33453'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "save embeddings"
      ],
      "metadata": {
        "id": "tZ8MDumri4L5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Assuming metadatas is a list of metadata dictionaries\n",
        "with open(\"metadata2.json\", \"w\", encoding=\"utf-8\") as f:   #metadata1 from 5k chunck size and metadata2 is from 1k chunck size\n",
        "    json.dump(metadatas, f, indent=2)"
      ],
      "metadata": {
        "id": "FqZrBLDlDtTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load saved embeddings\n",
        "import json\n",
        "# Open and read the metadata file\n",
        "with open(\"metadata2.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    metadatas = json.load(f)\n",
        "\n",
        "print(metadatas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwr1QqoydiYK",
        "outputId": "53b6cd35-d1ee-472f-a02f-c13ecd02f2bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'matched_concepts': 'epidermal growth factor receptor, epidermal growth factor, epidermal growth factor, breast cancer, breast cancer, breast cancer', 'node_ids': 'LP18396-9, LP18547-7, 1427158, LA14283-8, 174.0, 254837009', 'global_graph_indices': '22057, 22056, 26311, 17249, 24336, 33453'}, {'matched_concepts': 'breast cancer, breast cancer, breast cancer, pathogenesis, adjustments, lymph node', 'node_ids': 'LA14283-8, 254837009, 174.0, 263547006, 257738001, LP199987-1', 'global_graph_indices': '17249, 33453, 24336, 44451, 39045, 22778'}, {'matched_concepts': 'proliferation, growth factor, localization, fibroblasts, associated, additional', 'node_ids': '30217000, 81286007, LP200047-1, LP7234-0, LP28580-6, LP263791-8', 'global_graph_indices': '35600, 35679, 22753, 22185, 20620, 21089'}, {'matched_concepts': 'platelet-derived growth factor, protein kinase, as a result of, growth factor, identified, macrophage', 'node_ids': '10987005, LP15830-0, 19531003, 81286007, LP29257-0, 58986001', 'global_graph_indices': '40682, 23395, 34580, 35679, 18958, 29825'}, {'matched_concepts': 'complementary dna, chromosome 17, identified, chromosome, chromosome, carcinoma', 'node_ids': '70016006, LA21270-6, LP29257-0, 91272006, LP20948-3, LA15448-6', 'global_graph_indices': '29820, 17471, 18958, 31223, 21662, 17341'}, {'matched_concepts': 'intracellular, extracellular, chromosome, chromosome, medicine, tyrosine', 'node_ids': '83167003, 69320009, 91272006, LP20948-3, LA16120-0, LP15793-0', 'global_graph_indices': '30647, 39013, 31223, 21662, 16789, 23982'}, {'matched_concepts': 'is, c, a, i, l, a', 'node_ids': '258259005, LA14519-5, LP17763-1, LA15457-7, 258770004, 257982004', 'global_graph_indices': '40318, 21430, 21036, 22541, 37107, 41092'}, {'matched_concepts': 'as a result of, unidentified, unidentified, discussion, associated, laboratory', 'node_ids': '19531003, LA28280-8, 69910005, 223482009, LP28580-6, 261904005', 'global_graph_indices': '34580, 23995, 50580, 44446, 20620, 32327'}, {'matched_concepts': 'breast cancer, breast cancer, breast cancer, progesterone, progesterone, individual', 'node_ids': 'LA14283-8, 174.0, 254837009, LP14041-5, 8727, 385435006', 'global_graph_indices': '17249, 24336, 33453, 23365, 26358, 37475'}, {'matched_concepts': 'densitometry, association, individual, individual, scanning, arginase', 'node_ids': 'LP200395-4, 263534001, 385435006, LA12070-1, 258111003, LP15415-0', 'global_graph_indices': '20760, 41216, 37475, 17880, 56944, 21237'}, {'matched_concepts': 'performed, performed, transfer, receptor, receptor, protein', 'node_ids': 'LA19974-7, 398166005, LP97172-8, 116647005, LP21071-3, LP15838-3', 'global_graph_indices': '19961, 49916, 23903, 39716, 18302, 23389'}, {'matched_concepts': 'breast cancer, breast cancer, breast cancer, individual, individual, containing', 'node_ids': 'LA14283-8, 174.0, 254837009, LA12070-1, 385435006, 42504009', 'global_graph_indices': '17249, 24336, 33453, 17880, 37475, 48807'}, {'matched_concepts': 'electrophoresis, electrophoresis, electrophoresis, transferred, containing, solution', 'node_ids': '82664, LP6247-3, 703450007, LA14103-8, 42504009, 8537005', 'global_graph_indices': '284, 17995, 38017, 19365, 48807, 32471'}, {'matched_concepts': '30 minutes, exposed, then, room, vol, vol', 'node_ids': '1071000175108, 24932003, 421067001, LP101926-6, 118565006, LP6893-4', 'global_graph_indices': '50685, 30087, 57677, 23522, 51063, 20112'}, {'matched_concepts': 'breast tumor, breast tumor, discussion, containing, single, breast', 'node_ids': '126926005, LP36755-4, 223482009, 42504009, LA17717-2, LA4255-1', 'global_graph_indices': '33518, 21406, 44446, 48807, 20353, 21405'}, {'matched_concepts': 'association, temperature, temperature, containing, overnight, overnight', 'node_ids': '263534001, 246508008, MTHU009008, 42504009, LP40291-4, 255270004', 'global_graph_indices': '41216, 65911, 23794, 48807, 18979, 43489'}, {'matched_concepts': 'estrogen receptor, progesterone, progesterone, association, diagnosis, diagnosis', 'node_ids': 'LP18567-5, LP14041-5, 8727, 263534001, 439401001, MTHU008876', 'global_graph_indices': '22088, 23365, 26358, 41216, 55009, 20622'}, {'matched_concepts': 'combination, identified, regression, indicated, involved, axillary', 'node_ids': '89780004, LP29257-0, 48386003, 410535002, 248448006, LP220557-5', 'global_graph_indices': '32350, 18958, 50081, 56947, 57554, 17259'}, {'matched_concepts': 'breast cancer, breast cancer, breast cancer, recurrence, long-term, relapse', 'node_ids': 'LA14283-8, 174.0, 254837009, 246455001, 263803006, 263855007', 'global_graph_indices': '17249, 24336, 33453, 34205, 57051, 65393'}, {'matched_concepts': 'breast cancer, breast cancer, breast cancer, association, sufficient, sufficient', 'node_ids': 'LA14283-8, 174.0, 254837009, 263534001, 51117008, LA28126-3', 'global_graph_indices': '17249, 24336, 33453, 41216, 32337, 17031'}, {'matched_concepts': 'estrogen receptor, association, presence of, receptor, receptor, involved', 'node_ids': 'LP18567-5, 263534001, 10828004, LP21071-3, 116647005, LA26536-5', 'global_graph_indices': '22088, 41216, 65192, 18302, 39716, 20927'}, {'matched_concepts': 'disease behavior, mastectomy, recurrence, discussion, mastectomy, performed', 'node_ids': '277053001, 85.4, 246455001, 223482009, 116221009, LA19974-7', 'global_graph_indices': '35233, 13783, 34205, 44446, 64211, 19961'}, {'matched_concepts': 'association, radiation, radiation, radiation, superior, relapse', 'node_ids': '263534001, 256242009, 82107009, LA4351-8, 264217000, 263855007', 'global_graph_indices': '41216, 32243, 59960, 23456, 46487, 65393'}, {'matched_concepts': 'disease behavior, independent, independent, additional, prognosis, performed', 'node_ids': '277053001, LA12302-8, 371153006, LP263791-8, LP184342-6, LA19974-7', 'global_graph_indices': '35233, 20585, 54715, 21089, 23366, 19961'}, {'matched_concepts': 'performed, performed, between, disease, number, number', 'node_ids': 'LA19974-7, 398166005, 11896004, LA18199-2, 260299005, 57055006', 'global_graph_indices': '19961, 49916, 45301, 21952, 41178, 59781'}, {'matched_concepts': 'containing, identical, digestion, identical, weight, marked', 'node_ids': '42504009, LA14222-6, 17987008, 20323000, LP18015-5, LA17968-1', 'global_graph_indices': '48807, 16763, 32886, 30890, 24115, 16827'}, {'matched_concepts': 'breast cancer, growth factor, breast cancer, breast cancer, receptors, receptor', 'node_ids': 'LA14283-8, 81286007, 254837009, 174.0, LP21260-2, LP21071-3', 'global_graph_indices': '17249, 35679, 33453, 24336, 18303, 18302'}, {'matched_concepts': 'breast cancer, breast cancer, breast cancer, association, performed, performed', 'node_ids': '254837009, 174.0, LA14283-8, 263534001, 398166005, LA19974-7', 'global_graph_indices': '33453, 24336, 17249, 41216, 49916, 19961'}, {'matched_concepts': 'after, test, vol, vol, p, none', 'node_ids': '255234002, LA7556-9, LP6893-4, 118565006, LP15232-9, none', 'global_graph_indices': '60351, 18449, 20112, 51063, 16390, none'}, {'matched_concepts': 'discussion, regression, myc gene, disease, primary, primary', 'node_ids': '223482009, 48386003, LP36232-4, LA18199-2, 261424001, LA21208-6', 'global_graph_indices': '44446, 50081, 17524, 21952, 46566, 17440'}, {'matched_concepts': 'tumor progression, disease behavior, pathogenesis, association, frequently, diagnosis', 'node_ids': '419835002, 277053001, 263547006, 263534001, LA6482-9, MTHU008876', 'global_graph_indices': '36173, 35233, 44451, 41216, 20618, 20622'}, {'matched_concepts': 'pathogenesis, association, individual, expression, individual, frequently', 'node_ids': '263547006, 263534001, LA12070-1, 10012005, 385435006, LA6482-9', 'global_graph_indices': '44451, 41216, 17880, 36629, 37475, 20618'}, {'matched_concepts': 'breast cancer, breast cancer, breast cancer, progesterone, progesterone, adjustments', 'node_ids': 'LA14283-8, 174.0, 254837009, LP14041-5, 8727, 257738001', 'global_graph_indices': '17249, 24336, 33453, 23365, 26358, 39045'}, {'matched_concepts': 'disease progression, receptor protein, breast cancer, breast cancer, inappropriate, breast cancer', 'node_ids': 'LA28309-5, 69666007, 174.0, LA14283-8, 900000000000494007, 254837009', 'global_graph_indices': '18869, 59869, 24336, 17249, 50246, 33453'}, {'matched_concepts': 'small cell carcinoma, receptor protein, gene expression, breast cancer, breast cancer, breast cancer', 'node_ids': '11010461000119101, 69666007, 89551006, LA14283-8, 254837009, 174.0', 'global_graph_indices': '33188, 59869, 35060, 17249, 33453, 24336'}, {'matched_concepts': 'small cell carcinoma, identification, breast cancer, growth factor, breast cancer, breast cancer', 'node_ids': '11010461000119101, LP72776-5, 254837009, 81286007, LA14283-8, 174.0', 'global_graph_indices': '33188, 22557, 33453, 35679, 17249, 24336'}, {'matched_concepts': '1982, cell, 160, 16, 13, 12', 'node_ids': '277271000, 4421005, 732529007, LA14562-5, LA14559-1, LA14558-3', 'global_graph_indices': '52635, 29826, 29245, 17903, 20674, 20594'}, {'matched_concepts': 'yamamoto, cell, 22, 18, c, e', 'node_ids': '273246004, 4421005, 732598007, 732550003, LA14519-5, LP14534-9', 'global_graph_indices': '50569, 29826, 38709, 49914, 21430, 16500'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CombinedEmbeddingWrapper(Embeddings):\n",
        "    def __init__(self, combined_emb):\n",
        "        self.combined_emb = combined_emb\n",
        "\n",
        "    def embed_query(self, text: str) -> List[float]:\n",
        "        embedding, _ = self.combined_emb.embed_query(text)\n",
        "        return embedding\n",
        "\n",
        "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
        "        # call embed_query for each text and return just the embeddings.\n",
        "        return [self.embed_query(text) for text in texts]\n",
        "\n",
        "combined_embedding_wrapper = CombinedEmbeddingWrapper(combined_emb)"
      ],
      "metadata": {
        "id": "zVMrY9cTrDyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Chroma Vector DB"
      ],
      "metadata": {
        "id": "Bgw3kGH6i80R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db_save_path3='/content/drive/MyDrive/vector_db_humana3'\n"
      ],
      "metadata": {
        "id": "FYCspSgcDIQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the DB the first time"
      ],
      "metadata": {
        "id": "1RgHdbBOjBXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "\n",
        "\n",
        "# # Recreate the Chroma collection\n",
        "# db3 = Chroma.from_texts(\n",
        "#     texts=[d.page_content for d in docs],\n",
        "#     embedding=combined_embedding_wrapper,\n",
        "#     metadatas=[\n",
        "#         {\n",
        "#             \"matched_concepts\": m.get(\"matched_concepts\", \"\"),\n",
        "#             \"node_ids\": m.get(\"node_ids\", \"\"),\n",
        "#             \"global_graph_indices\": m.get(\"global_graph_indices\", \"\")\n",
        "#         }\n",
        "#         for m in metadatas\n",
        "#     ],\n",
        "#     persist_directory=db_save_path3,\n",
        "#     collection_name=\"rag-humana3\",\n",
        "#  #   client=client\n",
        "# )\n"
      ],
      "metadata": {
        "id": "cjqktqOrIl2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "extract the saved vector DB"
      ],
      "metadata": {
        "id": "f40yfMcAjEeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db3 = Chroma(\n",
        "    collection_name=\"rag-humana3\",\n",
        "    embedding_function=combined_embedding_wrapper,\n",
        "    persist_directory=db_save_path3,\n",
        ")\n",
        "\n",
        "# Check the number of documents loaded\n",
        "docs_loaded = db3._collection.count()  # or a similar method if provided\n",
        "print(\"Documents in collection:\", docs_loaded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWQVpumbaWw3",
        "outputId": "240b242e-c84f-422c-d9b5-2d89796f1d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-96d64e0b451f>:1: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
            "  db3 = Chroma(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents in collection: 38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(db3._collection.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNZh2jq6EYOu",
        "outputId": "e6f01020-7b96-4fbd-fb34-2d393dec580f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chatbot with llama 3 (8b)"
      ],
      "metadata": {
        "id": "NFMxH7hYI-_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA,StuffDocumentsChain\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from transformers import AutoTokenizer, TextStreamer, pipeline, BitsAndBytesConfig, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "XKXKl1NbFNIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "HUGGING_FACE_TOKEN='hf_xxxx'"
      ],
      "metadata": {
        "id": "gRdoweFWWrh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "Av-d72fgZb9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, token=HUGGING_FACE_TOKEN)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    token=HUGGING_FACE_TOKEN,\n",
        "    quantization_config=bnb_config\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "9a82e1ba91354e5095b22dcc1a74c0ef",
            "e66bea113c1946a5866912b203a826c5",
            "da40f056eebe412b9f3a368a9d070690",
            "4861541631df4cbd92cc274198460b72",
            "ec672e3be13b498999169ab36f62b346",
            "588f73f10ca74b7eba07fe3f8d34424a",
            "8b7047d9497644f68d7bb42d3cd08b1e",
            "ba367ceca0b54905b66c6fe57e99a2c8",
            "e5f875c9cff9417594df37c64b0e1224",
            "def70062fbe4478f9efa50e58d87e475",
            "5b864d2166fe4242ac62cd38a0aac8b9"
          ]
        },
        "id": "DfJGDLW9Xvvl",
        "outputId": "2f5c2f70-62d2-4127-ee7f-7dbb27c3111d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a82e1ba91354e5095b22dcc1a74c0ef"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the pipeline for text-generation\n",
        "\n",
        "\n",
        "# custom prompt template\n",
        "custom_template = \"\"\"\n",
        "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "You are a clinical expert. Use the following document excerpts to answer the question.\n",
        "Answer in 1 or 2 concise sentences. If you don't know, simply say \"I don't know.\" Do not repeat yourself.\n",
        "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=custom_template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "\n",
        "\n",
        "hf_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=1024,      #  input length\n",
        "    max_new_tokens=128,  # number of tokens to generate\n",
        " #   truncation=True,      # the input is truncated if too long\n",
        "temperature=0.1\n",
        "    )\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
        "\n",
        "retriever = db3.as_retriever(search_kwargs={\"k\": 1})\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    chain_type_kwargs={\"prompt\": prompt}  # Set the custom prompt here\n",
        ")\n",
        "# Example query\n",
        "query = \"How does HER-2/neu amplification affect survival in breast cancer?\"\n",
        "answer = qa_chain.run(query)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tD7fK31vHTs",
        "outputId": "1b786aa9-924e-4697-ba32-2a660e1de3b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Both `max_new_tokens` (=128) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rk249rVozezv",
        "outputId": "9ac2397f-130a-4ff5-8ea9-f75e608cc9c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are a clinical expert. Use the following document excerpts to answer the question.\n",
            "Answer in 1 or 2 concise sentences. If you don't know, simply say \"I don't know.\" Do not repeat yourself.\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "fes, in  breast cancer did not show amplification of these genes (33).  Alterations of non-tyrosine kinase-related proto-oncogenes in these  Table 3. Association between HER-2/neu amplification and disease parame- ters in combined surveys (189 patients). .  Factor Single 2 to S S to 20 >20 Total pt copy copies copies copies  H\"\"\"°\"\"\" receptor stf#US  ER+ 91 23 14 2 130 0.05  ER- 45 3 6 s 59  PgR+ 73 20 10 3 106 0.06  PgR- 63 6 10 4 83  Tumqr nu (antimetm)  :s2 31 9 4 0 44 0.19  2-5 62 13 7 2 84  >S 23 4 6 3 36  Unknown 20 0 3 2 25  Aae Rt tliRgnosis (yetm)  :sSO 37 13 8 2 60 0.11  >SO 88 13 10 s 116  Unknown 11 0 2 0 13  Number of positive lymph nodes  0 30 0 3 1 34 0.002  1-3 51 7 6 1 65  >3 38 18 8 4 68  Unknown 17 1 3 1 22  *ER and PgR arc as described in Table 1. tStatistical analyses for correlation of  HER-2/neu amplification with various disca,c parameters were performed by the x2  test. P values were computed after combining die cases with 5 to 20 and > 20 copies.  SCIENCE,\n",
            "\n",
            "Question: How does HER-2/neu amplification affect survival in breast cancer?\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "According to the table, HER-2/neu amplification is associated with a poorer prognosis (p=0.11) and a higher number of positive lymph nodes (p=0.002).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "UYfHOI_vjZlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "import json\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge import Rouge\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# onitialize ROUGE\n",
        "rouge = Rouge()\n",
        "\n",
        "def compute_metrics(response: str, ground_truth: str) -> tuple:\n",
        "    # tokenize both texts\n",
        "    reference_tokens = nltk.word_tokenize(ground_truth.lower())\n",
        "    hypothesis_tokens = nltk.word_tokenize(response.lower())\n",
        "\n",
        "    # compute BLEU score with smoothing\n",
        "    smoothing = SmoothingFunction().method1\n",
        "    bleu = sentence_bleu([reference_tokens], hypothesis_tokens, smoothing_function=smoothing)\n",
        "\n",
        "    # compute ROUGE-L F1 score\n",
        "    rouge_scores = rouge.get_scores(response, ground_truth)\n",
        "    rouge_l_f1 = rouge_scores[0]['rouge-l']['f']\n",
        "\n",
        "    # compute token-level F1 score based on unique token overlap\n",
        "    ref_set = set(reference_tokens)\n",
        "    hyp_set = set(hypothesis_tokens)\n",
        "    common = ref_set.intersection(hyp_set)\n",
        "    if not hyp_set or not ref_set:\n",
        "        precision = recall = token_f1 = 0\n",
        "    else:\n",
        "        precision = len(common) / len(hyp_set)\n",
        "        recall = len(common) / len(ref_set)\n",
        "        token_f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return bleu, rouge_l_f1, token_f1\n",
        "\n",
        "# evaluate a QA query and compute latency\n",
        "def evaluate_query(query: str, ground_truth: str) -> dict:\n",
        "    start_time = time.time()\n",
        "    response = qa_chain.run(query)\n",
        "    latency = time.time() - start_time\n",
        "\n",
        "    bleu, rouge_l_f1, token_f1 = compute_metrics(response, ground_truth)\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"response\": response,\n",
        "        \"latency\": latency,\n",
        "        \"bleu\": bleu,\n",
        "        \"rouge_l_f1\": rouge_l_f1,\n",
        "        \"token_f1\": token_f1\n",
        "    }\n",
        "\n",
        "#  queries and their corresponding ground truth answers.\n",
        "test_evaluations = [\n",
        "\n",
        "    {\n",
        "        \"query\": \"How does HER-2/neu amplification affect survival in breast cancer?\",\n",
        "        \"ground_truth\": (\n",
        "            \"HER-2/neu amplification correlates with shorter disease-free survival and overall survival, \"\n",
        "            \"indicating a worse prognosis for breast cancer patients.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What role do positive lymph nodes play in the prognosis of breast cancer?\",\n",
        "        \"ground_truth\": (\n",
        "            \"The number of positive lymph nodes is a key prognostic factor in breast cancer, affecting both relapse and overall survival.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"How is gene amplification measured in the study?\",\n",
        "        \"ground_truth\": (\n",
        "            \"Gene amplification was measured using Southern blot analysis with a 32P-labeled HER-2 probe, \"\n",
        "            \"followed by dilution analysis and densitometry.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What additional prognostic factors were considered in the analysis?\",\n",
        "        \"ground_truth\": (\n",
        "            \"Other prognostic factors included tumor size, hormonal receptor status, and patient age, \"\n",
        "            \"but HER-2/neu amplification remained a strong independent predictor.\"\n",
        "        )\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "evaluation_results = []\n",
        "for item in test_evaluations:\n",
        "    result = evaluate_query(item[\"query\"], item[\"ground_truth\"])\n",
        "    evaluation_results.append(result)\n",
        "\n",
        "#  evaluation results\n",
        "for result in evaluation_results:\n",
        "    print(f\"Query: {result['query']}\")\n",
        "    print(f\"Response: {result['response']}\")\n",
        "    print(f\"Latency: {result['latency']:.3f} seconds\")\n",
        "    print(f\"BLEU Score: {result['bleu']:.3f}\")\n",
        "    print(f\"ROUGE-L F1 Score: {result['rouge_l_f1']:.3f}\")\n",
        "    print(f\"Token-level F1 Score: {result['token_f1']:.3f}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trk9fCnWVA6B",
        "outputId": "f07a6b23-80b6-4e17-b60b-4dec90294693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Both `max_new_tokens` (=128) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Both `max_new_tokens` (=128) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Both `max_new_tokens` (=128) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Both `max_new_tokens` (=128) and `max_length`(=1024) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How does HER-2/neu amplification affect survival in breast cancer?\n",
            "Response: \n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are a clinical expert. Use the following document excerpts to answer the question.\n",
            "Answer in 1 or 2 concise sentences. If you don't know, simply say \"I don't know.\" Do not repeat yourself.\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "fes, in  breast cancer did not show amplification of these genes (33).  Alterations of non-tyrosine kinase-related proto-oncogenes in these  Table 3. Association between HER-2/neu amplification and disease parame- ters in combined surveys (189 patients). .  Factor Single 2 to S S to 20 >20 Total pt copy copies copies copies  H\"\"\"°\"\"\" receptor stf#US  ER+ 91 23 14 2 130 0.05  ER- 45 3 6 s 59  PgR+ 73 20 10 3 106 0.06  PgR- 63 6 10 4 83  Tumqr nu (antimetm)  :s2 31 9 4 0 44 0.19  2-5 62 13 7 2 84  >S 23 4 6 3 36  Unknown 20 0 3 2 25  Aae Rt tliRgnosis (yetm)  :sSO 37 13 8 2 60 0.11  >SO 88 13 10 s 116  Unknown 11 0 2 0 13  Number of positive lymph nodes  0 30 0 3 1 34 0.002  1-3 51 7 6 1 65  >3 38 18 8 4 68  Unknown 17 1 3 1 22  *ER and PgR arc as described in Table 1. tStatistical analyses for correlation of  HER-2/neu amplification with various disca,c parameters were performed by the x2  test. P values were computed after combining die cases with 5 to 20 and > 20 copies.  SCIENCE,\n",
            "\n",
            "Question: How does HER-2/neu amplification affect survival in breast cancer?\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "According to the table, HER-2/neu amplification is associated with a poorer prognosis (p=0.11) and a higher number of positive lymph nodes (p=0.002).\n",
            "Latency: 8.672 seconds\n",
            "BLEU Score: 0.002\n",
            "ROUGE-L F1 Score: 0.088\n",
            "Token-level F1 Score: 0.122\n",
            "--------------------------------------------------\n",
            "Query: What role do positive lymph nodes play in the prognosis of breast cancer?\n",
            "Response: \n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are a clinical expert. Use the following document excerpts to answer the question.\n",
            "Answer in 1 or 2 concise sentences. If you don't know, simply say \"I don't know.\" Do not repeat yourself.\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "fes, in  breast cancer did not show amplification of these genes (33).  Alterations of non-tyrosine kinase-related proto-oncogenes in these  Table 3. Association between HER-2/neu amplification and disease parame- ters in combined surveys (189 patients). .  Factor Single 2 to S S to 20 >20 Total pt copy copies copies copies  H\"\"\"°\"\"\" receptor stf#US  ER+ 91 23 14 2 130 0.05  ER- 45 3 6 s 59  PgR+ 73 20 10 3 106 0.06  PgR- 63 6 10 4 83  Tumqr nu (antimetm)  :s2 31 9 4 0 44 0.19  2-5 62 13 7 2 84  >S 23 4 6 3 36  Unknown 20 0 3 2 25  Aae Rt tliRgnosis (yetm)  :sSO 37 13 8 2 60 0.11  >SO 88 13 10 s 116  Unknown 11 0 2 0 13  Number of positive lymph nodes  0 30 0 3 1 34 0.002  1-3 51 7 6 1 65  >3 38 18 8 4 68  Unknown 17 1 3 1 22  *ER and PgR arc as described in Table 1. tStatistical analyses for correlation of  HER-2/neu amplification with various disca,c parameters were performed by the x2  test. P values were computed after combining die cases with 5 to 20 and > 20 copies.  SCIENCE,\n",
            "\n",
            "Question: What role do positive lymph nodes play in the prognosis of breast cancer?\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "The number of positive lymph nodes is significantly associated with prognosis, with patients having more than 3 positive lymph nodes having a poorer prognosis (p = 0.002).\n",
            "Latency: 9.658 seconds\n",
            "BLEU Score: 0.021\n",
            "ROUGE-L F1 Score: 0.104\n",
            "Token-level F1 Score: 0.139\n",
            "--------------------------------------------------\n",
            "Query: How is gene amplification measured in the study?\n",
            "Response: \n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are a clinical expert. Use the following document excerpts to answer the question.\n",
            "Answer in 1 or 2 concise sentences. If you don't know, simply say \"I don't know.\" Do not repeat yourself.\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "neu, was shown to be related  to, but distinct from, the c-erbB proto-oncogcnc (21). By means of  v-erbB and human EGFR as probes to screen human genomic and  complementary DNA (cDNA) libraries, two other groups indepen dently isolated human erbB--related genes that they called HER-2  (22) and c-erbB-2 (23). Subsequent sequence analysis and chromo somal mapping studies revealed all three genes (neu, c-erbB-2, and  HER-2) to be the same (22, 24, 25). A fourth group, also using v erbB as a probe, identified the same gene in a mammary carcinoma  cell line, MAC 117, where it was found to be amplified five-to ten fold (26).  This gene, which we will call HER-2/neu, encodes a new member  of the tyrosine kinase family; and is closely related to, but distinct  from, the EGFR gene (22). HER-2/neu differs from EGFR in that it  is  found on band q21 of chromosome 17 (22, 24, 25), as compared  to band p11-p13 of chromosome 7, where the EGFR gene is  located (27). Also, the HER-2/neu gene\n",
            "\n",
            "Question: How is gene amplification measured in the study?\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "In the study, gene amplification is measured as a five-to ten fold increase in the gene in a mammary carcinoma cell line, MAC 117.\n",
            "Latency: 7.948 seconds\n",
            "BLEU Score: 0.002\n",
            "ROUGE-L F1 Score: 0.102\n",
            "Token-level F1 Score: 0.149\n",
            "--------------------------------------------------\n",
            "Query: What additional prognostic factors were considered in the analysis?\n",
            "Response: \n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are a clinical expert. Use the following document excerpts to answer the question.\n",
            "Answer in 1 or 2 concise sentences. If you don't know, simply say \"I don't know.\" Do not repeat yourself.\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "the HER-2/, gcnc. Lanes I too arc serial dilutions (1:20, 1: 10, 1:5, and 1:2, rcspcctive ly)_ of the DNA sample in lane p. The filter was prepared and hybridiud with  a 32P-labclcd HER-2 probe as in Fig. 1. (B) Example of arginasc probe  hybridization to demonstrate that equivalent amounts of tumor DNA were  loaded into each lane. Rchybridization of filter containing lanes 30 to 40  (Fig.  1). The filter was first stripped of label by washing in a buffer made up  of SO% fomwnide, 3 x  SSC, and 0.1 % SOS  at 65°C for  20 minutes,  following by three successive washes of S minutes each in 0.1 x SSC at room  temperature. Filters were exposed overnight  on XAR-S film (Kodak) to  ensure removal of all radioactive probe, then rehybridiud as in Fig. 1 with a  32P-labclcd human arginasc gene probe (31).  in a blinded fashion, in that they were made without knowledge of  disease parameters. Analysis of the data for association bctwccn gene  amplification and a number of disease parameters was\n",
            "\n",
            "Question: What additional prognostic factors were considered in the analysis?\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "I don't know.\n",
            "Latency: 5.658 seconds\n",
            "BLEU Score: 0.002\n",
            "ROUGE-L F1 Score: 0.046\n",
            "Token-level F1 Score: 0.091\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Additional) use the saved metadata from clinical embedding"
      ],
      "metadata": {
        "id": "dl0d0ROUJ6sS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "\n",
        "\n",
        "# create the pipeline for llama3\n",
        "\n",
        "hf_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "  #  max_length=512,      #  input length\n",
        "    max_new_tokens=128,  # number of tokens to generate\n",
        "#    truncation=True,      # the input is truncated if too long\n",
        "temperature=0.1\n",
        "    )\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
        "\n",
        "\n",
        "# helper function that takes a document and a metadata dictionary\n",
        "def format_doc(doc, meta) -> str:\n",
        "    meta_str = (\n",
        "        f\"Matched Concepts: {meta.get('matched_concepts', 'N/A')}, \"\n",
        "        f\"Node IDs: {meta.get('node_ids', 'N/A')}, \"\n",
        "        f\"Global Graph Indices: {meta.get('global_graph_indices', 'N/A')}\"\n",
        "    )\n",
        "    return f\"{meta_str}\\nContent: {doc.page_content}\"\n",
        "\n",
        "# custom prompt template that includes metadata in the context.\n",
        "\n",
        "custom_template = \"\"\"\n",
        "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "You are a clinical expert. Use the following document excerpts (with associated metadata)  to answer the question.\n",
        "Answer in 1 or 2 concise sentences. If you don't know, simply say \"I don't know.\" Do not repeat yourself.\n",
        "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=custom_template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "# create the QA chain using the custom prompt.\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=db3.as_retriever(search_kwargs={\"k\": 1})\n",
        ")\n",
        "\n",
        "# example query\n",
        "query = \"How does HER-2/neu amplification affect survival in breast cancer?\"\n",
        "\n",
        "# retrieve relevant documents using the retriever\n",
        "retrieved_docs = db3.as_retriever(search_kwargs={\"k\": 1}).get_relevant_documents(query)\n",
        "\n",
        "# format the retrieved documents using the global metadatas list.\n",
        "# it assumes the order of retrieved_docs corresponds to the order of items in metadatas.\n",
        "formatted_docs = []\n",
        "for i, doc in enumerate(retrieved_docs):\n",
        "    meta = metadatas[i] if i < len(metadatas) else {}\n",
        "    formatted_docs.append(format_doc(doc, meta))\n",
        "\n",
        "# join the formatted documents into one context string.\n",
        "context = \"\\n\\n\".join(formatted_docs)\n",
        "\n",
        "#  the final prompt using our custom prompt template.\n",
        "final_prompt = prompt.format(context=context, question=query)\n",
        "print(\"Final Prompt:\\n\", final_prompt)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5vi-N_iJ_D7",
        "outputId": "12747cfd-9780-4067-ba6c-d5e7068c7d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Prompt:\n",
            " \n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are a clinical expert. Use the following document excerpts (with associated metadata)  to answer the question.\n",
            "Answer in 1 or 2 concise sentences. If you don't know, simply say \"I don't know.\" Do not repeat yourself.\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Matched Concepts: epidermal growth factor receptor, epidermal growth factor, epidermal growth factor, breast cancer, breast cancer, breast cancer, Node IDs: LP18396-9, LP18547-7, 1427158, LA14283-8, 174.0, 254837009, Global Graph Indices: 22057, 22056, 26311, 17249, 24336, 33453\n",
            "Content: fes, in  breast cancer did not show amplification of these genes (33).  Alterations of non-tyrosine kinase-related proto-oncogenes in these  Table 3. Association between HER-2/neu amplification and disease parame- ters in combined surveys (189 patients). .  Factor Single 2 to S S to 20 >20 Total pt copy copies copies copies  H\"\"\"°\"\"\" receptor stf#US  ER+ 91 23 14 2 130 0.05  ER- 45 3 6 s 59  PgR+ 73 20 10 3 106 0.06  PgR- 63 6 10 4 83  Tumqr nu (antimetm)  :s2 31 9 4 0 44 0.19  2-5 62 13 7 2 84  >S 23 4 6 3 36  Unknown 20 0 3 2 25  Aae Rt tliRgnosis (yetm)  :sSO 37 13 8 2 60 0.11  >SO 88 13 10 s 116  Unknown 11 0 2 0 13  Number of positive lymph nodes  0 30 0 3 1 34 0.002  1-3 51 7 6 1 65  >3 38 18 8 4 68  Unknown 17 1 3 1 22  *ER and PgR arc as described in Table 1. tStatistical analyses for correlation of  HER-2/neu amplification with various disca,c parameters were performed by the x2  test. P values were computed after combining die cases with 5 to 20 and > 20 copies.  SCIENCE,\n",
            "\n",
            "Question: How does HER-2/neu amplification affect survival in breast cancer?\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  LLM to generate an answer based on the final prompt.\n",
        "answer = llm(final_prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah0eJ_VRX5V-",
        "outputId": "d8d66e03-ce90-4bdb-faed-a99df288af0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Answer:\", answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzB_RgL0SL00",
        "outputId": "749b8eab-fe9a-451d-b557-5afe45bd353b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: \n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are a clinical expert. Use the following document excerpts (with associated metadata)  to answer the question.\n",
            "Answer in 1 or 2 concise sentences. If you don't know, simply say \"I don't know.\" Do not repeat yourself.\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Matched Concepts: epidermal growth factor receptor, epidermal growth factor, epidermal growth factor, breast cancer, breast cancer, breast cancer, Node IDs: LP18396-9, LP18547-7, 1427158, LA14283-8, 174.0, 254837009, Global Graph Indices: 22057, 22056, 26311, 17249, 24336, 33453\n",
            "Content: fes, in  breast cancer did not show amplification of these genes (33).  Alterations of non-tyrosine kinase-related proto-oncogenes in these  Table 3. Association between HER-2/neu amplification and disease parame- ters in combined surveys (189 patients). .  Factor Single 2 to S S to 20 >20 Total pt copy copies copies copies  H\"\"\"°\"\"\" receptor stf#US  ER+ 91 23 14 2 130 0.05  ER- 45 3 6 s 59  PgR+ 73 20 10 3 106 0.06  PgR- 63 6 10 4 83  Tumqr nu (antimetm)  :s2 31 9 4 0 44 0.19  2-5 62 13 7 2 84  >S 23 4 6 3 36  Unknown 20 0 3 2 25  Aae Rt tliRgnosis (yetm)  :sSO 37 13 8 2 60 0.11  >SO 88 13 10 s 116  Unknown 11 0 2 0 13  Number of positive lymph nodes  0 30 0 3 1 34 0.002  1-3 51 7 6 1 65  >3 38 18 8 4 68  Unknown 17 1 3 1 22  *ER and PgR arc as described in Table 1. tStatistical analyses for correlation of  HER-2/neu amplification with various disca,c parameters were performed by the x2  test. P values were computed after combining die cases with 5 to 20 and > 20 copies.  SCIENCE,\n",
            "\n",
            "Question: How does HER-2/neu amplification affect survival in breast cancer?\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "I don't know. The provided text does not explicitly state how HER-2/neu amplification affects survival in breast cancer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "bLnsV0nxRc9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import json\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge import Rouge\n",
        "\n",
        "\n",
        "# initialize ROUGE\n",
        "rouge = Rouge()\n",
        "\n",
        "def compute_metrics(response: str, ground_truth: str) -> tuple:\n",
        "    # tokenize both texts.\n",
        "    reference_tokens = nltk.word_tokenize(ground_truth.lower())\n",
        "    hypothesis_tokens = nltk.word_tokenize(response.lower())\n",
        "\n",
        "    # compute BLEU score with smoothing.\n",
        "    smoothing = SmoothingFunction().method1\n",
        "    bleu = sentence_bleu([reference_tokens], hypothesis_tokens, smoothing_function=smoothing)\n",
        "\n",
        "    # compute ROUGE-L F1 score.\n",
        "    rouge_scores = rouge.get_scores(response, ground_truth)\n",
        "    rouge_l_f1 = rouge_scores[0]['rouge-l']['f']\n",
        "\n",
        "    # compute token-level F1 based on unique token overlap.\n",
        "    ref_set = set(reference_tokens)\n",
        "    hyp_set = set(hypothesis_tokens)\n",
        "    common = ref_set.intersection(hyp_set)\n",
        "    if not hyp_set or not ref_set:\n",
        "        precision = recall = token_f1 = 0\n",
        "    else:\n",
        "        precision = len(common) / len(hyp_set)\n",
        "        recall = len(common) / len(ref_set)\n",
        "        token_f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return bleu, rouge_l_f1, token_f1\n",
        "\n",
        "def evaluate_query_with_metadata(query: str, ground_truth: str) -> dict:\n",
        "    # dtart timer to measure latency.\n",
        "    start_time = time.time()\n",
        "    retrieved_docs = db3.as_retriever(search_kwargs={\"k\": 1}).get_relevant_documents(query)\n",
        "\n",
        "# format the retrieved documents using the global metadatas list.\n",
        "# it assumes the order of retrieved_docs corresponds to the order of items in metadatas.\n",
        "    formatted_docs = []\n",
        "    for i, doc in enumerate(retrieved_docs):\n",
        "      meta = metadatas[i] if i < len(metadatas) else {}\n",
        "      formatted_docs.append(format_doc(doc, meta))\n",
        "\n",
        "# join the formatted documents into one context string.\n",
        "    context = \"\\n\\n\".join(formatted_docs)\n",
        "\n",
        "# build the final prompt using our custom prompt template.\n",
        "    final_prompt = prompt.format(context=context, question=query)\n",
        "\n",
        "    response =llm(final_prompt)\n",
        "    latency = time.time() - start_time\n",
        "\n",
        "    # Compute evaluation metrics.\n",
        "    bleu, rouge_l_f1, token_f1 = compute_metrics(response, ground_truth)\n",
        "\n",
        "    # retrieve documents in context that includes metadata\n",
        "\n",
        "    retrieved_metadata =  context\n",
        "\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"response\": response,\n",
        "        \"latency\": latency,\n",
        "        \"bleu\": bleu,\n",
        "        \"rouge_l_f1\": rouge_l_f1,\n",
        "        \"token_f1\": token_f1,\n",
        "        \"retrieved_metadata\": retrieved_metadata\n",
        "    }\n",
        "\n",
        "# sets of test evaluations.\n",
        "test_evaluations = [\n",
        "\n",
        "    {\n",
        "        \"query\": \"How does HER-2/neu amplification affect survival in breast cancer?\",\n",
        "        \"ground_truth\": (\n",
        "            \"HER-2/neu amplification correlates with shorter disease-free survival and overall survival, \"\n",
        "            \"indicating a worse prognosis for breast cancer patients.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What role do positive lymph nodes play in the prognosis of breast cancer?\",\n",
        "        \"ground_truth\": (\n",
        "            \"The number of positive lymph nodes is a key prognostic factor in breast cancer, affecting both relapse and overall survival.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"How is gene amplification measured in the study?\",\n",
        "        \"ground_truth\": (\n",
        "            \"Gene amplification was measured using Southern blot analysis with a 32P-labeled HER-2 probe, \"\n",
        "            \"followed by dilution analysis and densitometry.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What additional prognostic factors were considered in the analysis?\",\n",
        "        \"ground_truth\": (\n",
        "            \"Other prognostic factors included tumor size, hormonal receptor status, and patient age, \"\n",
        "            \"but HER-2/neu amplification remained a strong independent predictor.\"\n",
        "        )\n",
        "    }\n",
        "]\n",
        "\n",
        "# evaluate each query and store results.\n",
        "evaluation_results = []\n",
        "for item in test_evaluations:\n",
        "    result = evaluate_query_with_metadata(item[\"query\"], item[\"ground_truth\"])\n",
        "    evaluation_results.append(result)\n",
        "\n",
        "# print evaluation results.\n",
        "for result in evaluation_results:\n",
        "    print(f\"Query: {result['query']}\")\n",
        "    print(f\"Response: {result['response']}\")\n",
        "    print(f\"Latency: {result['latency']:.3f} seconds\")\n",
        "    print(f\"BLEU Score: {result['bleu']:.3f}\")\n",
        "    print(f\"ROUGE-L F1 Score: {result['rouge_l_f1']:.3f}\")\n",
        "    print(f\"Token-level F1 Score: {result['token_f1']:.3f}\")\n",
        "    print(\"Retrieved Metadata:\", result['retrieved_metadata'])\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3esuwo0RPm5",
        "outputId": "e4e57265-43b0-44f7-abcf-3f86d813c8b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How does HER-2/neu amplification affect survival in breast cancer?\n",
            "Response: \n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are a clinical expert. Use the following document excerpts (with associated metadata)  to answer the question.\n",
            "Answer in 1 or 2 concise sentences. If you don't know, simply say \"I don't know.\" Do not repeat yourself.\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Matched Concepts: epidermal growth factor receptor, epidermal growth factor, epidermal growth factor, breast cancer, breast cancer, breast cancer, Node IDs: LP18396-9, LP18547-7, 1427158, LA14283-8, 174.0, 254837009, Global Graph Indices: 22057, 22056, 26311, 17249, 24336, 33453\n",
            "Content: fes, in  breast cancer did not show amplification of these genes (33).  Alterations of non-tyrosine kinase-related proto-oncogenes in these  Table 3. Association between HER-2/neu amplification and disease parame- ters in combined surveys (189 patients). .  Factor Single 2 to S S to 20 >20 Total pt copy copies copies copies  H\"\"\"°\"\"\" receptor stf#US  ER+ 91 23 14 2 130 0.05  ER- 45 3 6 s 59  PgR+ 73 20 10 3 106 0.06  PgR- 63 6 10 4 83  Tumqr nu (antimetm)  :s2 31 9 4 0 44 0.19  2-5 62 13 7 2 84  >S 23 4 6 3 36  Unknown 20 0 3 2 25  Aae Rt tliRgnosis (yetm)  :sSO 37 13 8 2 60 0.11  >SO 88 13 10 s 116  Unknown 11 0 2 0 13  Number of positive lymph nodes  0 30 0 3 1 34 0.002  1-3 51 7 6 1 65  >3 38 18 8 4 68  Unknown 17 1 3 1 22  *ER and PgR arc as described in Table 1. tStatistical analyses for correlation of  HER-2/neu amplification with various disca,c parameters were performed by the x2  test. P values were computed after combining die cases with 5 to 20 and > 20 copies.  SCIENCE,\n",
            "\n",
            "Question: How does HER-2/neu amplification affect survival in breast cancer?\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "I don't know. The provided text does not explicitly state how HER-2/neu amplification affects survival in breast cancer.\n",
            "Latency: 8.584 seconds\n",
            "BLEU Score: 0.002\n",
            "ROUGE-L F1 Score: 0.069\n",
            "Token-level F1 Score: 0.103\n",
            "Retrieved Metadata: Matched Concepts: epidermal growth factor receptor, epidermal growth factor, epidermal growth factor, breast cancer, breast cancer, breast cancer, Node IDs: LP18396-9, LP18547-7, 1427158, LA14283-8, 174.0, 254837009, Global Graph Indices: 22057, 22056, 26311, 17249, 24336, 33453\n",
            "Content: fes, in  breast cancer did not show amplification of these genes (33).  Alterations of non-tyrosine kinase-related proto-oncogenes in these  Table 3. Association between HER-2/neu amplification and disease parame- ters in combined surveys (189 patients). .  Factor Single 2 to S S to 20 >20 Total pt copy copies copies copies  H\"\"\"°\"\"\" receptor stf#US  ER+ 91 23 14 2 130 0.05  ER- 45 3 6 s 59  PgR+ 73 20 10 3 106 0.06  PgR- 63 6 10 4 83  Tumqr nu (antimetm)  :s2 31 9 4 0 44 0.19  2-5 62 13 7 2 84  >S 23 4 6 3 36  Unknown 20 0 3 2 25  Aae Rt tliRgnosis (yetm)  :sSO 37 13 8 2 60 0.11  >SO 88 13 10 s 116  Unknown 11 0 2 0 13  Number of positive lymph nodes  0 30 0 3 1 34 0.002  1-3 51 7 6 1 65  >3 38 18 8 4 68  Unknown 17 1 3 1 22  *ER and PgR arc as described in Table 1. tStatistical analyses for correlation of  HER-2/neu amplification with various disca,c parameters were performed by the x2  test. P values were computed after combining die cases with 5 to 20 and > 20 copies.  SCIENCE,\n",
            "--------------------------------------------------\n",
            "Query: What role do positive lymph nodes play in the prognosis of breast cancer?\n",
            "Response: \n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are a clinical expert. Use the following document excerpts (with associated metadata)  to answer the question.\n",
            "Answer in 1 or 2 concise sentences. If you don't know, simply say \"I don't know.\" Do not repeat yourself.\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Matched Concepts: epidermal growth factor receptor, epidermal growth factor, epidermal growth factor, breast cancer, breast cancer, breast cancer, Node IDs: LP18396-9, LP18547-7, 1427158, LA14283-8, 174.0, 254837009, Global Graph Indices: 22057, 22056, 26311, 17249, 24336, 33453\n",
            "Content: fes, in  breast cancer did not show amplification of these genes (33).  Alterations of non-tyrosine kinase-related proto-oncogenes in these  Table 3. Association between HER-2/neu amplification and disease parame- ters in combined surveys (189 patients). .  Factor Single 2 to S S to 20 >20 Total pt copy copies copies copies  H\"\"\"°\"\"\" receptor stf#US  ER+ 91 23 14 2 130 0.05  ER- 45 3 6 s 59  PgR+ 73 20 10 3 106 0.06  PgR- 63 6 10 4 83  Tumqr nu (antimetm)  :s2 31 9 4 0 44 0.19  2-5 62 13 7 2 84  >S 23 4 6 3 36  Unknown 20 0 3 2 25  Aae Rt tliRgnosis (yetm)  :sSO 37 13 8 2 60 0.11  >SO 88 13 10 s 116  Unknown 11 0 2 0 13  Number of positive lymph nodes  0 30 0 3 1 34 0.002  1-3 51 7 6 1 65  >3 38 18 8 4 68  Unknown 17 1 3 1 22  *ER and PgR arc as described in Table 1. tStatistical analyses for correlation of  HER-2/neu amplification with various disca,c parameters were performed by the x2  test. P values were computed after combining die cases with 5 to 20 and > 20 copies.  SCIENCE,\n",
            "\n",
            "Question: What role do positive lymph nodes play in the prognosis of breast cancer?\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "The presence of positive lymph nodes is associated with a poorer prognosis in breast cancer, with a significant correlation observed in the study, as indicated by the statistical analysis (p = 0.002).\n",
            "Latency: 10.901 seconds\n",
            "BLEU Score: 0.017\n",
            "ROUGE-L F1 Score: 0.100\n",
            "Token-level F1 Score: 0.124\n",
            "Retrieved Metadata: Matched Concepts: epidermal growth factor receptor, epidermal growth factor, epidermal growth factor, breast cancer, breast cancer, breast cancer, Node IDs: LP18396-9, LP18547-7, 1427158, LA14283-8, 174.0, 254837009, Global Graph Indices: 22057, 22056, 26311, 17249, 24336, 33453\n",
            "Content: fes, in  breast cancer did not show amplification of these genes (33).  Alterations of non-tyrosine kinase-related proto-oncogenes in these  Table 3. Association between HER-2/neu amplification and disease parame- ters in combined surveys (189 patients). .  Factor Single 2 to S S to 20 >20 Total pt copy copies copies copies  H\"\"\"°\"\"\" receptor stf#US  ER+ 91 23 14 2 130 0.05  ER- 45 3 6 s 59  PgR+ 73 20 10 3 106 0.06  PgR- 63 6 10 4 83  Tumqr nu (antimetm)  :s2 31 9 4 0 44 0.19  2-5 62 13 7 2 84  >S 23 4 6 3 36  Unknown 20 0 3 2 25  Aae Rt tliRgnosis (yetm)  :sSO 37 13 8 2 60 0.11  >SO 88 13 10 s 116  Unknown 11 0 2 0 13  Number of positive lymph nodes  0 30 0 3 1 34 0.002  1-3 51 7 6 1 65  >3 38 18 8 4 68  Unknown 17 1 3 1 22  *ER and PgR arc as described in Table 1. tStatistical analyses for correlation of  HER-2/neu amplification with various disca,c parameters were performed by the x2  test. P values were computed after combining die cases with 5 to 20 and > 20 copies.  SCIENCE,\n",
            "--------------------------------------------------\n",
            "Query: How is gene amplification measured in the study?\n",
            "Response: \n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are a clinical expert. Use the following document excerpts (with associated metadata)  to answer the question.\n",
            "Answer in 1 or 2 concise sentences. If you don't know, simply say \"I don't know.\" Do not repeat yourself.\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Matched Concepts: epidermal growth factor receptor, epidermal growth factor, epidermal growth factor, breast cancer, breast cancer, breast cancer, Node IDs: LP18396-9, LP18547-7, 1427158, LA14283-8, 174.0, 254837009, Global Graph Indices: 22057, 22056, 26311, 17249, 24336, 33453\n",
            "Content: neu, was shown to be related  to, but distinct from, the c-erbB proto-oncogcnc (21). By means of  v-erbB and human EGFR as probes to screen human genomic and  complementary DNA (cDNA) libraries, two other groups indepen dently isolated human erbB--related genes that they called HER-2  (22) and c-erbB-2 (23). Subsequent sequence analysis and chromo somal mapping studies revealed all three genes (neu, c-erbB-2, and  HER-2) to be the same (22, 24, 25). A fourth group, also using v erbB as a probe, identified the same gene in a mammary carcinoma  cell line, MAC 117, where it was found to be amplified five-to ten fold (26).  This gene, which we will call HER-2/neu, encodes a new member  of the tyrosine kinase family; and is closely related to, but distinct  from, the EGFR gene (22). HER-2/neu differs from EGFR in that it  is  found on band q21 of chromosome 17 (22, 24, 25), as compared  to band p11-p13 of chromosome 7, where the EGFR gene is  located (27). Also, the HER-2/neu gene\n",
            "\n",
            "Question: How is gene amplification measured in the study?\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "In the study, gene amplification is measured as a five-to ten fold increase in the gene in a mammary carcinoma cell line, MAC 117.\n",
            "Latency: 8.511 seconds\n",
            "BLEU Score: 0.002\n",
            "ROUGE-L F1 Score: 0.087\n",
            "Token-level F1 Score: 0.138\n",
            "Retrieved Metadata: Matched Concepts: epidermal growth factor receptor, epidermal growth factor, epidermal growth factor, breast cancer, breast cancer, breast cancer, Node IDs: LP18396-9, LP18547-7, 1427158, LA14283-8, 174.0, 254837009, Global Graph Indices: 22057, 22056, 26311, 17249, 24336, 33453\n",
            "Content: neu, was shown to be related  to, but distinct from, the c-erbB proto-oncogcnc (21). By means of  v-erbB and human EGFR as probes to screen human genomic and  complementary DNA (cDNA) libraries, two other groups indepen dently isolated human erbB--related genes that they called HER-2  (22) and c-erbB-2 (23). Subsequent sequence analysis and chromo somal mapping studies revealed all three genes (neu, c-erbB-2, and  HER-2) to be the same (22, 24, 25). A fourth group, also using v erbB as a probe, identified the same gene in a mammary carcinoma  cell line, MAC 117, where it was found to be amplified five-to ten fold (26).  This gene, which we will call HER-2/neu, encodes a new member  of the tyrosine kinase family; and is closely related to, but distinct  from, the EGFR gene (22). HER-2/neu differs from EGFR in that it  is  found on band q21 of chromosome 17 (22, 24, 25), as compared  to band p11-p13 of chromosome 7, where the EGFR gene is  located (27). Also, the HER-2/neu gene\n",
            "--------------------------------------------------\n",
            "Query: What additional prognostic factors were considered in the analysis?\n",
            "Response: \n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are a clinical expert. Use the following document excerpts (with associated metadata)  to answer the question.\n",
            "Answer in 1 or 2 concise sentences. If you don't know, simply say \"I don't know.\" Do not repeat yourself.\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Matched Concepts: epidermal growth factor receptor, epidermal growth factor, epidermal growth factor, breast cancer, breast cancer, breast cancer, Node IDs: LP18396-9, LP18547-7, 1427158, LA14283-8, 174.0, 254837009, Global Graph Indices: 22057, 22056, 26311, 17249, 24336, 33453\n",
            "Content: the HER-2/, gcnc. Lanes I too arc serial dilutions (1:20, 1: 10, 1:5, and 1:2, rcspcctive ly)_ of the DNA sample in lane p. The filter was prepared and hybridiud with  a 32P-labclcd HER-2 probe as in Fig. 1. (B) Example of arginasc probe  hybridization to demonstrate that equivalent amounts of tumor DNA were  loaded into each lane. Rchybridization of filter containing lanes 30 to 40  (Fig.  1). The filter was first stripped of label by washing in a buffer made up  of SO% fomwnide, 3 x  SSC, and 0.1 % SOS  at 65°C for  20 minutes,  following by three successive washes of S minutes each in 0.1 x SSC at room  temperature. Filters were exposed overnight  on XAR-S film (Kodak) to  ensure removal of all radioactive probe, then rehybridiud as in Fig. 1 with a  32P-labclcd human arginasc gene probe (31).  in a blinded fashion, in that they were made without knowledge of  disease parameters. Analysis of the data for association bctwccn gene  amplification and a number of disease parameters was\n",
            "\n",
            "Question: What additional prognostic factors were considered in the analysis?\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "I don't know.\n",
            "Latency: 6.492 seconds\n",
            "BLEU Score: 0.002\n",
            "ROUGE-L F1 Score: 0.039\n",
            "Token-level F1 Score: 0.088\n",
            "Retrieved Metadata: Matched Concepts: epidermal growth factor receptor, epidermal growth factor, epidermal growth factor, breast cancer, breast cancer, breast cancer, Node IDs: LP18396-9, LP18547-7, 1427158, LA14283-8, 174.0, 254837009, Global Graph Indices: 22057, 22056, 26311, 17249, 24336, 33453\n",
            "Content: the HER-2/, gcnc. Lanes I too arc serial dilutions (1:20, 1: 10, 1:5, and 1:2, rcspcctive ly)_ of the DNA sample in lane p. The filter was prepared and hybridiud with  a 32P-labclcd HER-2 probe as in Fig. 1. (B) Example of arginasc probe  hybridization to demonstrate that equivalent amounts of tumor DNA were  loaded into each lane. Rchybridization of filter containing lanes 30 to 40  (Fig.  1). The filter was first stripped of label by washing in a buffer made up  of SO% fomwnide, 3 x  SSC, and 0.1 % SOS  at 65°C for  20 minutes,  following by three successive washes of S minutes each in 0.1 x SSC at room  temperature. Filters were exposed overnight  on XAR-S film (Kodak) to  ensure removal of all radioactive probe, then rehybridiud as in Fig. 1 with a  32P-labclcd human arginasc gene probe (31).  in a blinded fashion, in that they were made without knowledge of  disease parameters. Analysis of the data for association bctwccn gene  amplification and a number of disease parameters was\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### template for the Chatbot"
      ],
      "metadata": {
        "id": "iZCRSfevjp0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import re\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "def create_qa_chatbot(model_name: str, hf_token: str, db3, search_k: int = 1):\n",
        "    \"\"\"\n",
        "    Sets up a QA chatbot using the specified model and Chroma vector store.\n",
        "\n",
        "    Parameters:\n",
        "      model_name (str): Model identifier (e.g., \"meta-llama/Llama-3.1-8B-Instruct\").\n",
        "      hf_token (str): Your Hugging Face access token.\n",
        "      db3: A pre-loaded Chroma vector store.\n",
        "      search_k (int): Number of documents to retrieve.\n",
        "\n",
        "    Returns:\n",
        "      A function that runs an interactive Q&A loop.\n",
        "    \"\"\"\n",
        "\n",
        "    # configure quantization for 4-bit inference.\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    )\n",
        "\n",
        "    # load tokenizer and model with your token.\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        token=hf_token,\n",
        "        quantization_config=bnb_config\n",
        "    )\n",
        "\n",
        "    #   custom prompt template in Llama-3 style.\n",
        "    custom_template = \"\"\"\n",
        "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "You are a clinical expert. Use the following document excerpts to answer the question.\n",
        "Answer in 1 or 2 concise sentences. If you don't know, simply say \"I don't know.\" Do not repeat yourself.\n",
        "<|eot_id|>\n",
        "<|start_header_id|>user<|end_header_id|>\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "<|eot_id|>\n",
        "<|start_header_id|>assistant<|end_header_id|>\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(template=custom_template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "    # create the Hugging Face pipeline.\n",
        "    hf_pipeline = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=128,  # Number of tokens to generate\n",
        "        temperature=0.1\n",
        "    )\n",
        "\n",
        "    # wrap the pipeline for LangChain.\n",
        "    llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
        "\n",
        "    # set up the retriever from saved Chroma vector store.\n",
        "    retriever = db3.as_retriever(search_kwargs={\"k\": search_k})\n",
        "\n",
        "    # create the QA chain using the \"stuff\" chain type and our custom prompt.\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        chain_type_kwargs={\"prompt\": prompt}\n",
        "    )\n",
        "\n",
        "    # helper function to extract the answer text after the assistant header token.\n",
        "    def extract_answer(raw_text: str) -> str:\n",
        "        parts = re.split(r\"<\\|start_header_id\\|>assistant<\\|end_header_id\\|>\", raw_text)\n",
        "        if len(parts) > 1:\n",
        "            return parts[1].strip()\n",
        "        return raw_text.strip()\n",
        "\n",
        "    # interactive Q&A loop function.\n",
        "    def run_chatbot():\n",
        "        while True:\n",
        "            query = input(\"Enter your question (or type 'exit' to quit): \")\n",
        "            if query.lower() == \"exit\":\n",
        "                print(\"Exiting Q&A.\")\n",
        "                break\n",
        "            raw_answer = qa_chain.run(query)\n",
        "            answer = extract_answer(raw_answer)\n",
        "            print(\"Answer:\", answer)\n",
        "\n",
        "    return run_chatbot\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l8gAHTrE88Fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# usage:\n",
        "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "HUGGING_FACE_TOKEN = 'hf_xxxx'\n",
        "# db3 is the loaded Chroma vector store\n",
        "run_chatbot = create_qa_chatbot(model_name, HUGGING_FACE_TOKEN, db3, search_k=1)\n",
        "run_chatbot()"
      ],
      "metadata": {
        "id": "-WSPHH9ru-GB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chatboat with google T5"
      ],
      "metadata": {
        "id": "HJuSOe0cHIur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, LEDForConditionalGeneration, pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "\n",
        "\n",
        "model_name = \"google/flan-t5-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "\n",
        "custom_template = \"\"\"\n",
        "You are a clinical expert. Use the following document excerpts to answer the question.\n",
        "Answer in 1 or 2 sentences. If you don't know, just say I don't know. Do not make up answers.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=custom_template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "# create the pipeline for text2text-generation\n",
        "hf_pipeline = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=512,      #  input length\n",
        "  #  max_new_tokens=512,  # number of tokens to generate\n",
        "   # truncation=True,\n",
        "temperature=0.1\n",
        "    )\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
        "\n",
        "retriever = db3.as_retriever(search_kwargs={\"k\": 1})\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    chain_type_kwargs={\"prompt\": prompt}  # Set the custom prompt here\n",
        ")\n",
        "\n",
        "# Example query\n",
        "query = \"How does HER-2/neu amplification affect survival in breast cancer?\"\n",
        "answer = qa_chain.run(query)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtCtwtasEIu4",
        "outputId": "5a8228c5-3b12-4aef-bd63-7e68e7051510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8Ide7o2H7fn",
        "outputId": "90f27e18-4f01-43c9-d0b2-f2710e331ee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't know\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "y7Btzu_4wYDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "import json\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge import Rouge\n",
        "\n",
        "\n",
        "\n",
        "# initialize ROUGE\n",
        "rouge = Rouge()\n",
        "\n",
        "def compute_metrics(response: str, ground_truth: str) -> tuple:\n",
        "    # tokenize both texts\n",
        "    reference_tokens = nltk.word_tokenize(ground_truth.lower())\n",
        "    hypothesis_tokens = nltk.word_tokenize(response.lower())\n",
        "\n",
        "    # compute BLEU score with smoothing\n",
        "    smoothing = SmoothingFunction().method1\n",
        "    bleu = sentence_bleu([reference_tokens], hypothesis_tokens, smoothing_function=smoothing)\n",
        "\n",
        "    # compute ROUGE-L F1 score\n",
        "    rouge_scores = rouge.get_scores(response, ground_truth)\n",
        "    rouge_l_f1 = rouge_scores[0]['rouge-l']['f']\n",
        "\n",
        "    # compute token-level F1 score based on unique token overlap\n",
        "    ref_set = set(reference_tokens)\n",
        "    hyp_set = set(hypothesis_tokens)\n",
        "    common = ref_set.intersection(hyp_set)\n",
        "    if not hyp_set or not ref_set:\n",
        "        precision = recall = token_f1 = 0\n",
        "    else:\n",
        "        precision = len(common) / len(hyp_set)\n",
        "        recall = len(common) / len(ref_set)\n",
        "        token_f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return bleu, rouge_l_f1, token_f1\n",
        "\n",
        "# evaluate a QA query and compute latency\n",
        "def evaluate_query(query: str, ground_truth: str) -> dict:\n",
        "    start_time = time.time()\n",
        "    response = qa_chain.run(query)\n",
        "    latency = time.time() - start_time\n",
        "\n",
        "    bleu, rouge_l_f1, token_f1 = compute_metrics(response, ground_truth)\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"response\": response,\n",
        "        \"latency\": latency,\n",
        "        \"bleu\": bleu,\n",
        "        \"rouge_l_f1\": rouge_l_f1,\n",
        "        \"token_f1\": token_f1\n",
        "    }\n",
        "\n",
        "# queries and their corresponding ground truth answers.\n",
        "test_evaluations = [\n",
        "\n",
        "    {\n",
        "        \"query\": \"How does HER-2/neu amplification affect survival in breast cancer?\",\n",
        "        \"ground_truth\": (\n",
        "            \"HER-2/neu amplification correlates with shorter disease-free survival and overall survival, \"\n",
        "            \"indicating a worse prognosis for breast cancer patients.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What role do positive lymph nodes play in the prognosis of breast cancer?\",\n",
        "        \"ground_truth\": (\n",
        "            \"The number of positive lymph nodes is a key prognostic factor in breast cancer, affecting both relapse and overall survival.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"How is gene amplification measured in the study?\",\n",
        "        \"ground_truth\": (\n",
        "            \"Gene amplification was measured using Southern blot analysis with a 32P-labeled HER-2 probe, \"\n",
        "            \"followed by dilution analysis and densitometry.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What additional prognostic factors were considered in the analysis?\",\n",
        "        \"ground_truth\": (\n",
        "            \"Other prognostic factors included tumor size, hormonal receptor status, and patient age, \"\n",
        "            \"but HER-2/neu amplification remained a strong independent predictor.\"\n",
        "        )\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "evaluation_results = []\n",
        "for item in test_evaluations:\n",
        "    result = evaluate_query(item[\"query\"], item[\"ground_truth\"])\n",
        "    evaluation_results.append(result)\n",
        "\n",
        "# evaluation results\n",
        "for result in evaluation_results:\n",
        "    print(f\"Query: {result['query']}\")\n",
        "    print(f\"Response: {result['response']}\")\n",
        "    print(f\"Latency: {result['latency']:.3f} seconds\")\n",
        "    print(f\"BLEU Score: {result['bleu']:.3f}\")\n",
        "    print(f\"ROUGE-L F1 Score: {result['rouge_l_f1']:.3f}\")\n",
        "    print(f\"Token-level F1 Score: {result['token_f1']:.3f}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLdqbpWDHi1h",
        "outputId": "78e2d8f5-0c70-4cc6-ade9-7256c54f6fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How does HER-2/neu amplification affect survival in breast cancer?\n",
            "Response: I don't know\n",
            "Latency: 3.226 seconds\n",
            "BLEU Score: 0.000\n",
            "ROUGE-L F1 Score: 0.000\n",
            "Token-level F1 Score: 0.000\n",
            "--------------------------------------------------\n",
            "Query: What role do positive lymph nodes play in the prognosis of breast cancer?\n",
            "Response: I don't know\n",
            "Latency: 3.997 seconds\n",
            "BLEU Score: 0.000\n",
            "ROUGE-L F1 Score: 0.000\n",
            "Token-level F1 Score: 0.000\n",
            "--------------------------------------------------\n",
            "Query: How is gene amplification measured in the study?\n",
            "Response: using v erbB as a probe\n",
            "Latency: 3.970 seconds\n",
            "BLEU Score: 0.004\n",
            "ROUGE-L F1 Score: 0.167\n",
            "Token-level F1 Score: 0.231\n",
            "--------------------------------------------------\n",
            "Query: What additional prognostic factors were considered in the analysis?\n",
            "Response: I don't know\n",
            "Latency: 3.263 seconds\n",
            "BLEU Score: 0.000\n",
            "ROUGE-L F1 Score: 0.000\n",
            "Token-level F1 Score: 0.000\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary"
      ],
      "metadata": {
        "id": "IwBLJW6Qv9zw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It has shown that Llama 3 (3.1 8b) outperformed Google T5 on the Q&A case. Overall, the evaluation showed mixed performance (given the 4 testing questions): for the query on survival impact, the chatbot correctly identified that HER-2/neu amplification is associated with poorer prognosis and a higher number of positive lymph nodes, though its BLEU, ROUGE-L, and token-level F1 scores were very low, indicating limited overlap with the ground truth. For the question regarding the role of positive lymph nodes, it produced a more focused answer noting the significance of having more than three nodes, with slightly improved metrics. However, when asked about additional prognostic factors, the model repeatedly defaulted to \"I don't know,\" reflecting a gap in its context understanding or retrieval process. Latency ranged from around 5.7 to 9.7 seconds per query, indicating resaonble response times.\n",
        "\n",
        "To test more comprehensively, I thonk can build a test set of many diverse query-ground truth pairs and automate the evaluation. For example, can store a list/DF of queries and expected answers, then loop through them to compute evaluation metrics (BLEU, ROUGE, token-level F1, latency, etc.), aggregate the results, and generate summary statistics and visualizations."
      ],
      "metadata": {
        "id": "VxQYoUELMQ3_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UE3wgeAgphls"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}